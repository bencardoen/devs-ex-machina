Several similar \textsf{DEVS} simulation tools have already been implemented, though they differ in several key aspects.
We discuss several dimensions of related work, as we try to compromise between different tools.

In terms of code design and philosophy, \textit{dxex} is most related to \textit{PythonPDEVS}~\cite{PythonPDEVS}.
Performance of \textit{PythonPDEVS} was decent through the use of ``hints'' from the modeler.
In this spirit, we offer users the possibility to choose between different synchronization protocols.
This allows users to choose the most appropriate synchronization protocol, depending on the model.
Contrary to \textit{PythonPDEVS}, however, \textit{dxex} doesn't support distributed simulation~\cite{JDF}, model migrations~\cite{PythonPDEVS2}, or activity hints~\cite{PythonPDEVS_ACTIMS}.

Although \textit{PythonPDEVS} offers very fast turnaround cycles, simulation performance was easily outdone by compiled simulation kernels.
In terms of performance, \textit{adevs}~\cite{adevs} offered much faster simulation, at the cost of compilation time.
While this is beneficial for long running simulations, small simulations are therefore negatively impacted.
The turnaround cycle in \textit{adevs} is much slower, specifically because the complete simulation kernel is implemented using templates in header files.
As a result, the complete simulation kernel has to be compiled again every time.
Similarly to \textit{vle}~\cite{vle} and \textit{PowerDEVS}~\cite{PowerDEVS}, \textit{dxex} compromises by separating the simulation kernel into a shared library.
After the initial compilation of the simulation tool, only the model has to be compiled and linked to the shared library.
This significantly shortens the turnaround cycle, while still offering good performance.
In terms of performance, \textit{dxex} is shown to be competitive with \textit{adevs}.
Despite its high performance, \textit{adevs} does not support optimistic synchronization, which we have shown to be highly relevant for certain kinds of models.

Previous \textsf{DEVS} simulation tools have already implemented multiple synchronization protocols, though none have done so in a strictly modular way that allows straightforward protocol switching for a single given model.
For example, \textit{adevs} only supports conservative synchronization, and \textit{vle} only supports experiment-level parallelism (\textit{i.e.}, run independent experiments in parallel).
Closest to our support for multiple synchronization protocols is \textit{CD++}~\cite{CD++}.
For \textit{CD++}, both a conservative (\textit{CCD++}~\cite{CCD++}) and optimistic (\textit{PCD++}~\cite{PCD++}) variant exist.
Despite the implementation of both protocols, they are entirely different projects.
Some features might therefore be implemented in \textit{CCD++} and not in \textit{PCD++}, or vice versa.
And while this might not be a problem at this time, the problem will only get worse when each project follows its own course.
\textit{Dxex}, on the other hand, is a single project, where the choice of synchronization protocol is a simple configuration option.
\textit{CD++}, however, implements both conservative and optimistic synchronization for distributed simulation, whereas we limit ourselves to parallel simulation. 
A new architecture for sequential PDEVS simulation has been introduced in \cite{SeqPDEVSArch} with promising performance results.
This algorithm achieves a speedup by using \textit{xP} synchronization.
By limiting our approach to pure parallel simulation (\textit{i.e.}, no distributed simulation), we are able to achieve higher speedups through the use of shared memory communication. 
Recent work on parallel speedup in DEVS investigates theoretical limits of PDEVS~\cite{activitypdevs, amdahlpdevs}

In the \textsf{PDES} community, the problem of choosing between synchronization protocols is well known and documented~\cite{Jha:1994:UFC:195291.182480}.
The challenges of implementing such runtime switching have previously been explored already~\cite{Das:1996:APP:256562.256602}, and implemented~\cite{perumalla2005musik}.
Our contribution entails bringing this same feature to the \textsf{Parallel DEVS} community, further expanding upon our support for multiple synchronization protocols.

Model allocation and its impact on parallel performance has previously also been studied in the \textsf{PDES} community~\cite{PDESpartitioning}.
Referenced as partitioning of the simulation model, most studies distinguish between communication and computation as the two dimensions to partition over.
Partitioning a model is identified as an issue to achieve scalability~\cite{Scalability}. 
Some research in this context has been done for \textsf{Parallel DEVS}~\cite{PDEVSpartitioning, NonFragmenting}.
Our contribution studies the effect of partitioning with emphasis on the effect of communication between kernels and in the presence of a flattened hierarchy. 
We focus on static partitioning since this is a limiting factor for our conservative synchronization implementation which does not support model migration.
Model migration, as implemented by \textit{PythonPDEVS}, might be an interesting addition to model allocation.

In summary, \textit{dxex} tries to find the middle ground between the concepts of \textit{PythonPDEVS}, the performance of \textit{adevs}, and the multiple synchronization protocols of \textit{CD++}.
To further profit from our multiple synchronization protocols in a single tool, we further added runtime switching between synchronization protocols and model allocation support.
