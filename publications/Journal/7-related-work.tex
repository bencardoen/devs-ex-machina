Several similar \textsf{DEVS} simulation tools have already been implemented, though they differ in several key aspects.
We discuss several dimensions of related work, as we try to compromise between different tools.

In terms of code design and philosophy, dxex is most related to PythonPDEVS~\cite{PythonPDEVS}.
Performance of PythonPDEVS was still decent through the use of ``hints'' from the modeler.
In this spirit, we offer users the possibility to choose between different synchronization protocols.
This allows users to choose the most appropriate synchronization protocol, depending on the model.
Contrary to PythonPDEVS, however, dxex doesn't support distributed simulation~\cite{JDF}, model migrations~\cite{PythonPDEVS2}, or activity hints~\cite{PythonPDEVS_ACTIMS}.

Although PythonPDEVS offers very fast turnaround cycles, simulation performance was easily outdone by compiled simulation kernels.
In terms of performance, adevs~\cite{adevs} offered much faster simulation, at the cost of a significant compilation time.
The turnaround cycle in adevs is much slower though, specifically because the complete simulation kernel is implemented using templates in header files.
As a result, the complete simulation kernel has to be compiled again every time.
Similarly to vle~\cite{vle} and PowerDEVS~\cite{PowerDEVS}, dxex compromises by separating the simulation kernel into a shared library.
After the initial compilation of the simulation tool, only the model has to be compiled and linked to the shared library.
This significantly shortens the turnaround cycle, while still offering good performance.
In terms of performance, dxex is shown to be competitive with adevs.
Despite its high performance, adevs does not support optimistic synchronization, which we have shown to be highly relevant.

Previous \textsf{DEVS} simulation tools have already implemented multiple synchronization protocols, though none have done it in a strictly modular way that allows straightforward protocol switching for a single given model.
For example, adevs only supports conservative synchronization, and vle only supports experiment-level parallelism (\textit{i.e.}, run multiple experiments concurrently).
Closest to our support for multiple synchronization protocols is CD++~\cite{CD++}.
For CD++, both a conservative (CCD++~\cite{CCD++}) and optimistic (PCD++)~\cite{PCD++}) variant exist.
Despite the implementation of both protocols, they are different projects entirely.
Some features might therefore be implemented in CCD++ and not in PCD++, or vice versa.
And while this might not yet be that significant a problem to this day, this problem will only get worse when each project follows its own course.
Dxex, on the other hand, is a single project, where the choice of synchronization protocol is a simple configuration.
CD++, however, implements both conservative and optimistic synchronization for distributed simulation, whereas we limit ourselves to parallel simulation.
By limiting our approach to parallel simulation, we are able to achieve higher speedups through the use of shared memory communication.

In the PDES community, the problem of choosing between synchronization protocols is well known and documented~\cite{Jha:1994:UFC:195291.182480}.
The challenges of implementing such runtime switching have previously been explored already~\cite{Das:1996:APP:256562.256602}, and an implementation was given by, for example~\cite{perumalla2005musik}.
Our contribution entails bringing this same feature to the DEVS community, further expanding upon our unique feature of multiple synchronization protocols.

Model allocation and its impact on parallel performance has previously also been studied in the PDES community~\cite{PDESpartitioning}.
Referenced as partitioning of the simulation model, most studies distinguish between communication overhead and computational distribution (load balancing) as the two dimensions to partition over.
Partitioning a simulation model is identified as an issue to achieve scalability~\cite{Scalability}. 
Some research in the context of Parallel DEVS has been done, where they turn their attention to load balancing and communication overhead~\cite{PDEVSpartitioning}.
Our contribution studies the effect of partitioning with emphasis on the effect of communication between processes and in the presence of a flattened hierarchy. 
We focus on static partitioning since this is a limiting factor for our conservative synchronization implementation which does not support model relocation.
Model relocation, as implemented by PythonPDEVS~\cite{PythonPDEVS2}, might be an interesting addition to only model allocation at the start of simulation.

In summary, dxex tries to find the middle ground between the concepts of PythonPDEVS, the performance of adevs, and the multiple synchronization protocols of CD++.
To further profit from our multiple synchronization protocols in a single tool, we further added runtime switching between synchronization protocols and model allocation support.
